{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conventional way to import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a dataset of Chipotle orders directly from a URL and store the results in a DataFrame\n",
    "#orders = pd.read_table('http://bit.ly/chiporders')\n",
    "\n",
    "# read a dataset of Chipotle orders directly from a file stored on disk and store the results in a DataFrame\n",
    "orders = pd.read_table('data/chipotle.tsv')\n",
    "type(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('data/movieusers.tsv') # seprator '|' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('data/movieusers.tsv',sep='|').head() # first row was selected as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('data/movieusers.tsv',sep='|', header=None) # default numbers are assigned to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining user defined Column names\n",
    "ucol = ['id','age','gender','occupation','code']\n",
    "user = pd.read_table('data/movieusers.tsv',sep='|', header=None,names=ucol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()\n",
    "# Please read skiprow and skipfooter parameter of read_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two important objects in Pandas 1) Data Frame (consist of rows and cols) 2) Panda Series (cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to read only selected columns\n",
    "ufo = pd.read_csv('data/ufo.csv', usecols=['City','State'])\n",
    "#### OR ####\n",
    "#ufo = pd.read_csv('data/ufo.csv', usecols=[0,3])\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read only top rows\n",
    "ufo = pd.read_csv('data/ufo.csv', nrows=4)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ufo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to select a particular series from DF. its case sensitive\n",
    "ufo[\"City\"] # it returns first thirty and last thirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ufo[\"City\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.City # Dot notation can also be used for series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Important Note: When ever a series is added to DF, it automatically becomes attribute of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to select series of Colors Reported?\n",
    "# if there is space in the name then dot notation will not help and col name should not match with built in fuction like shape, head etc\n",
    "ufo['Colors Reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to concatenate two series\n",
    "#'abd'+'dee'\n",
    "ufo.City + ' , ' + ufo.State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a new series in DF don't use do notation, For assignment it is necessary that we should use barcket notation\n",
    "ufo['Location'] = ufo.City + ' , ' + ufo.State\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dtypes # example of attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# please read the data from imdb_1000 and calculate sum of star_rating and max duration of movie ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows statistics of numeric colums\n",
    "ufo.describe() # example of method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.shape # example of attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Rename Columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.rename(columns={'Colors Reported': 'Colors_Reported', 'Shape Reported':'Shape_Reported'}) \n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace = True to show the impact in existing DF\n",
    "ufo.rename(columns={'Colors Reported': 'Colors_Reported', 'Shape Reported':'Shape_Reported'},inplace=True) \n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns names while reading\n",
    "#import pandas as pd\n",
    "mycol = ['city','color reported', 'shape reported','state','time', 'location']\n",
    "ufo = pd.read_csv('data/ufo.csv',names=mycol)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have thousands of col with spaces in between\n",
    "ufo.columns = ufo.columns.str.replace(' ','_')\n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remove Columns from DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use axis = 1 to drop column\n",
    "ufo.drop('shape_reported', axis=1) # this will not effect the current object i.e., ufo. You can confirm this by using ufo.columns command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ufo.head()\n",
    "ufo.drop('location', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop multiple columns, use list of strings\n",
    "ufo.drop(['city', 'time'], axis=1, inplace=True)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use axis = 0 to drop rows\n",
    "ufo.drop([0,1],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "how to sort DF or Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('data/imdb_1000.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies.title.sort_values(ascending=False)\n",
    "movies['title'].sort_values() # it returns panda series and default is assending order\n",
    "#movies['title'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting entire DF on a particular topic\n",
    "movies.sort_values('title',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by mulitple columns\n",
    "#movies.head()\n",
    "movies.sort_values(['star_rating','duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select movies with duration > 200 ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how we can more simplify the above code???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies[movies.duration>=200]\n",
    "#movies[movies.duration>=200].duration\n",
    "#movies[movies.duration>=200]['duration']\n",
    "movies.loc[movies.duration>=200, 'duration'] # recommended approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Multiple filters ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies[movies.duration>=200 & movies.genre=='Crime'] # this will not work\n",
    "movies[(movies.duration>=200) & (movies.genre=='Crime')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show the which contains record of 'Drama','Crime','Action' genere ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we use multiple condition on single attribute \n",
    "#movies[(movies.genre=='Drama') | (movies.genre=='Crime') | (movies.genre=='Action')]\n",
    "# or we can use isin method\n",
    "movies[movies.genre.isin(['Drama','Crime','Action'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('data/drinks.csv')\n",
    "drinks.dtypes\n",
    "import numpy as np\n",
    "drinks.select_dtypes(include=[np.number]).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drinks.index\n",
    "#drinks.columns\n",
    "#drinks.loc['Brazil','beer_servings']\n",
    "#drinks.index.name = None # removing the word \"country\" from rows#\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('data/drinks.csv')\n",
    "drinks.set_index('country', inplace=True)\n",
    "people = pd.Series([3000000, 85000], index=['Albania', 'Andorra'], name='population')\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(drinks.beer_servings * people).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate a series to DF\n",
    "pd.concat([drinks,people], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String Methods in PD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Change Data types of series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks['beer_servings'] = drinks.beer_servings.astype(float)\n",
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to change the data type while reading CSV\n",
    "drinks = pd.read_csv('data/drinks.csv',dtype={'beer_servings':float})\n",
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the mean of 'beer_serving' w.r.t Asia ???\n",
    "## calculate the mean of 'beer_serving' w.r.t continet ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks[drinks.continent=='Asia'].beer_servings.mean()\n",
    "#drinks[drinks.continent=='Europe'].beer_servings.mean()\n",
    "#drinks[drinks.continent=='Africa'].beer_servings.mean()\n",
    "#drinks.groupby('continent').beer_servings.mean()\n",
    "#drinks.groupby('continent').beer_servings.max()\n",
    "#drinks.groupby('continent').beer_servings.min()\n",
    "#drinks.groupby('continent').beer_servings.agg(['count','max','min','mean'])\n",
    "#drinks.groupby('continent').mean() # if we don't specify col then it will create mean of all cols\n",
    "#drinks.groupby('continent').max()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Handeling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ufo = pd.read_csv('data/ufo.csv')\n",
    "ufo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.isnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.notnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.isnull().sum() # returns no. of sums of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo[ufo.City.isnull()]\n",
    "#ufo[ufo.City.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to deal with missing value, there are many possible solution and some of them are given below\n",
    "ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(how='any').shape # drops all rows that contains ANY of five columns have missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(how='all').shape # drops all rows that contains ALL of five columns have missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape # drops all rows that contains ANY of two columns have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(subset=['City', 'Shape Reported'], how='all').shape # drops all rows that contains All of two columns have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ufo['Shape Reported'].value_counts()\n",
    "ufo['Shape Reported'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True) # replace NaN with Various,\n",
    "#ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True, method=None) # replace NaN with Various,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo['Shape Reported'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[0,:] # zeroth row and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[[0,1,2],:] # return 0,1 and 2nd row with all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[0:2,:] \n",
    "# or\n",
    "ufo.loc[0:2] # its not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cols\n",
    "ufo.loc[:,'City']\n",
    "ufo.loc[:,['City','State']]\n",
    "ufo.loc[:,'City':'State'] # all col between City and State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo[ufo.City=='Alma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[ufo.City=='Alma',:] # label based indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to DF smaller and Faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(ufo.State.unique()))\n",
    "#len(sorted(ufo.City.unique()))\n",
    "#ufo.City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.DataFrame({'Roll no':[1,2,3,4,5],'Name':['Ali','Ahmed','Qasim', 'Ayesha','Aleena'],'GPA':['good','good','very good','good','Excellent']})\n",
    "mydf.sort_values('GPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['GPA'] = mydf.GPA.astype('category', categories=['good', 'very good', 'Excellent'], ordered=True)\n",
    "mydf.GPA\n",
    "mydf.sort_values('GPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.loc[mydf.GPA > 'good',:] # we can condition on 'good' now becuase of above statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('data/imdb_1000.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.content_rating.isnull().sum() #counting the missing values in the 'content_rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.content_rating.isnull()] # rows containing null in 'content_rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.content_rating.value_counts(dropna=False) # unique values of Content Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.content_rating=='NOT RATED'].head() # to show \"NOT RATED\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.content_rating=='NOT RATED'].content_rating.head() # then, select the 'content_rating' Series from those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'content_rating' Series has not changed\n",
    "movies.content_rating.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the 'NOT RATED' values with 'NaN' (does not cause a SettingWithCopyWarning)\n",
    "movies.loc[movies.content_rating=='NOT RATED', 'content_rating'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time, the 'content_rating' Series has changed\n",
    "movies.content_rating.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = movies.loc[movies.star_rating >= 9, :]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies # 'top_movies' DataFrame has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1) # 'movies' DataFrame has not been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicitly create a copy of 'movies'\n",
    "top_movies = movies.loc[movies.star_rating >= 9, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas now knows that you are updating a copy instead of a view (does not cause a SettingWithCopyWarning)\n",
    "top_movies.loc[0, 'duration'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'top_movies' DataFrame has been updated\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies # show only sixty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current setting for the 'max_rows' option\n",
    "pd.get_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overwrite the current setting so that all rows will be displayed\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies # now show all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the 'max_rows' option to its default\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'max_columns' option is similar to 'max_rows'\n",
    "pd.get_option('display.max_columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
